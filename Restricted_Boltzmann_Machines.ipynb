{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b48830-50ae-471b-b020-1680bf43bc1d",
   "metadata": {},
   "source": [
    "# Building a Recommender System with Restricted Boltzmann Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acce4e5-1bb4-49d5-9031-5832000dd484",
   "metadata": {},
   "source": [
    "A Boltzmann Machine (BM) is a stochastic, generative neural network that can learn the probability distribution of its training data. It treats visible and hidden nodes symmetrically, unlike regular neural networks which treat the hidden nodes differently than the visible nodes.\n",
    "\n",
    "BMs generate their own data based on the joint probability distribution learned from the training data. They are considered generative models as they can generate new samples from the learned distribution. In contrast, discriminative models like regular neural networks learn the conditional probability of the labels given the inputs.\n",
    "\n",
    "During training, BM learns the interactions between nodes in an unsupervised manner. It adjusts the weights to capture the statistical structure in the training data. After training on proper data, BM understands how the system works in its normal (acceptable) state and can help identify abnormal states.\n",
    "\n",
    "Due to the exponential growth in the number of hidden nodes as the visible nodes increase, Restricted Boltzmann Machines (RBMs) are typically used instead of full BMs. RBMs impose structure by only having connections between visible and hidden nodes, not between nodes of the same type.\n",
    "\n",
    "During the training of RBMs, contrastive divergence is commonly used as an approximation to Maximum Likelihood learning due to its computational simplicity. This involves running a Markov chain for a few steps to estimate the gradient.\n",
    "\n",
    "After training, RBMs can be used for applications like collaborative filtering, dimensionality reduction, feature learning, etc. The latent representations captured by the hidden nodes can be useful for downstream tasks.\n",
    "\n",
    "In summary, BMs/RBMs are stochastic, generative models that learn the joint probability distribution of inputs unsupervised. Their learned representations of the data distribution can help with various applications in domains like computer vision, natural language processing, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1269299d-df95-4999-8634-6353fa9753fe",
   "metadata": {},
   "source": [
    "## Project Overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e308b2-5020-483f-ab5c-1a6071fb4ecf",
   "metadata": {},
   "source": [
    "This project is an exploration into the application of deep learning for building a recommender system, a crucial tool in today's data-driven world. The project focuses on the implementation of Restricted Boltzmann Machines (RBM), a type of artificial neural network known for its effectiveness in recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254d266b-e7b7-4ca7-8eaa-0c2c66d9e384",
   "metadata": {},
   "source": [
    "#### Key Components and Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c28a5f-9ea3-42e8-867d-cd3176ec6d23",
   "metadata": {},
   "source": [
    "1. **Data Preparation:**\n",
    "\n",
    "* The project begins by importing and processing data from the **MovieLens dataset**, consisting of movies, users, and ratings. This dataset serves as the foundation for the recommender system.\n",
    "\n",
    "2. **Data Conversion and Preprocessing:**\n",
    "\n",
    "* The data is converted into Torch tensors, making it compatible with PyTorch, a popular deep learning framework.\n",
    "* Ratings are converted into binary values to represent user preferences, simplifying the recommendation task (liked or not liked).\n",
    "\n",
    "3. **RBM Architecture:**\n",
    "\n",
    "* A Restricted Boltzmann Machine is designed with a visible layer (movies) and a hidden layer.\n",
    "* The RBM includes learnable parameters (weights and biases) that capture patterns in user-movie interactions.\n",
    "\n",
    "4. Training the RBM:\n",
    "\n",
    "* The RBM is trained using stochastic gradient descent.\n",
    "* During training, the RBM learns to represent the underlying structure of user preferences in an unsupervised manner.\n",
    "\n",
    "5. Testing and Evaluation:\n",
    "\n",
    "* The trained RBM is used to predict user preferences and make movie recommendations.\n",
    "* The system's performance is evaluated using test data to assess its accuracy and effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d3e569-4a55-4f09-af2c-ea39b17ed524",
   "metadata": {},
   "source": [
    "#### Key Insights:\n",
    "\n",
    "- The project provides insights into the benefits of using RBMs in recommendation systems. RBMs can effectively capture complex user preferences and generate movie recommendations.\n",
    "- It explores the concept of stochastic learning and unsupervised training, demonstrating how RBMs can learn the structure of user-movie interactions without labeled data.\n",
    "\n",
    "#### Dataset Source:\n",
    "\n",
    "- The MovieLens dataset, obtained from https://grouplens.org/datasets/movielens, serves as the data source for this project. This dataset contains user ratings of movies and is commonly used for building recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e81519-850c-42a0-a3a9-07afbcdb0c4d",
   "metadata": {},
   "source": [
    "#### Significant features of the MovieLens datasets\n",
    "\n",
    "- Standard benchmark datasets: The datasets like MovieLens 100K, 1M, 10M and 20M have become standard benchmarks for evaluating and comparing recommender system algorithms. Using these standardized datasets allows for easy reproducibility and comparison of results across different studies. \n",
    "\n",
    "- Large sizes: The 10M and 20M datasets contain 10 million and 20 million ratings respectively, providing a large amount of data to train and evaluate algorithms. The smaller datasets are also useful for faster experimentation.\n",
    "\n",
    "- Rich metadata: Along with ratings, the datasets also contain metadata about users, movies and tags which can be useful for developing and evaluating content-based and contextual recommendation techniques. \n",
    "\n",
    "- Easy access: The datasets are freely and publicly available for download from the GroupLens website, making them easily accessible for researchers and students.\n",
    "\n",
    "- Extended features: Some datasets like tag genome and YouTube datasets provide additional tag relevance scores and metadata that can enable new recommendation modeling techniques.\n",
    "\n",
    "- Long history of use: Being used widely for over a decade, they provide a good baseline and benchmark to compare performance over time as algorithms evolve. \n",
    "\n",
    "So in summary, the standardized sizes, rich metadata, easy availability and long history of these datasets make them very useful resources for recommender system research and education."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc594e-e3cf-4ac6-bdd7-11b52b780cdb",
   "metadata": {},
   "source": [
    "This project showcases the practical application of deep learning in the field of recommendation systems, providing valuable experience in the development and evaluation of AI-driven solutions for personalized content recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29746b6f-affa-4bf7-8935-5946ca6930cf",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2177060d-2ef1-4356-929b-80281e788572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cdcbfc99-9252-4f83-8b29-89305a72506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn                # the module to implement neural network\n",
    "import torch.nn.parallel             # for parallel computation\n",
    "import torch.optim as optim          # the optimizer\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable  # for stochastic gradient discent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ed131-bd90-4005-ac08-deba035625c8",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d465e0c2-044c-4890-8be0-f965d33f1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "# the separator is '::'\n",
    "# We use **encoding = latin-1** because some movie names have special characters.\n",
    "# since our columns have no names, we add header = None.\n",
    "# We will use just the first column which is the movie id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f810be1-a699-4938-b058-d5a1c7baed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                                   1                             2\n",
      "0  1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1  2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2  3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3  4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4  5  Father of the Bride Part II (1995)                        Comedy\n",
      "(3883, 3)\n"
     ]
    }
   ],
   "source": [
    "print(movies.head())\n",
    "print(movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0f525d8a-bce9-439e-a4e3-818e91c1c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "# The first column is the user ID.\n",
    "# The second column corresponds to the movie ID.\n",
    "# The third column corresponds to the user's rating of that movie (1 to 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e99d166d-1e23-41d7-901f-bb7958102fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0     1  2          3\n",
      "0  1  1193  5  978300760\n",
      "1  1   661  3  978302109\n",
      "2  1   914  3  978301968\n",
      "3  1  3408  4  978300275\n",
      "4  1  2355  5  978824291\n",
      "(1000209, 4)\n"
     ]
    }
   ],
   "source": [
    "print(ratings.head())\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e45dcc-d7fd-411c-a49a-6b0ac9e1927c",
   "metadata": {},
   "source": [
    "## Preparing the training set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e79cfa4-76d6-4a06-adbb-7d4c0995621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1  1.1  5  874965758\n",
      "0  1    2  3  876893171\n",
      "1  1    3  4  878542960\n",
      "2  1    4  3  876893119\n",
      "3  1    5  3  889751712\n",
      "4  1    7  4  875071561\n"
     ]
    }
   ],
   "source": [
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
    "print(training_set.head())\n",
    "training_set = np.array(training_set, dtype = 'int')\n",
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
    "test_set = np.array(test_set, dtype = 'int')\n",
    "\n",
    "# In u1.base, the elements of each row are separated by a tab; hence delimiter = '\\t'\n",
    "# The 1st column is the user ID\n",
    "# The 2nd column is the movie ID\n",
    "# The 3rd column is the rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3d4b9049-7e12-4db5-9b79-01df74b4b02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79999, 4)\n",
      "(19999, 4)\n"
     ]
    }
   ],
   "source": [
    "print(training_set.shape)\n",
    "print(test_set.shape)\n",
    "# 80/20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1552d1ad-7475-4136-9fd6-9d10119da3cc",
   "metadata": {},
   "source": [
    "## Getting the number of users and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc21ac41-0917-4681-b07f-c200cced4407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users: 943\n",
      "number of movies: 1682\n"
     ]
    }
   ],
   "source": [
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
    "print('number of users:',nb_users)\n",
    "print('number of movies:', nb_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe599d3-4ab8-4b80-bf8e-05b77b7dddf9",
   "metadata": {},
   "source": [
    "## Converting the data into an array with users in lines and movies in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a753747-fea3-46dc-8de5-0f74d1a215ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0eed6d-ce53-44c6-9b26-ba952a10992f",
   "metadata": {},
   "source": [
    "## Converting the data into Torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57907ae7-0c83-420a-a2e7-7833e6045a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99e77d4a-e2ca-4918-b0f4-b5893b4933f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([943, 1682])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b9294a7f-8568-4187-ba87-c4b7ae604f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32eb96-6e23-4080-8c1e-3a3bce8cf3dd",
   "metadata": {},
   "source": [
    "## Converting the ratings into binary ratings 1 (Liked) or 0 (Not Liked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "63b877df-d798-437e-9edb-b0b619d96a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[training_set == 0] = -1\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set == 3] = 1\n",
    "training_set[training_set == 4] = 1\n",
    "training_set[training_set == 5] = 1\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set == 3] = 1\n",
    "test_set[test_set == 4] = 1\n",
    "test_set[test_set == 5] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8642448-4e16-4e2b-bcfd-8c025ddaf9b8",
   "metadata": {},
   "source": [
    "## Creating the architecture of the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46da1f13-b666-4105-acac-f25682fb6283",
   "metadata": {},
   "source": [
    "Restricted Boltzmann Machine is a probability graphical model. \n",
    "\n",
    "h = v.Wt + a \n",
    "\n",
    "v = W.h + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "43421833-c37c-4368-af37-da3f8fb14564",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.randn(1, nh)\n",
    "        self.b = torch.randn(1, nv)\n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)\n",
    "nv = len(training_set[0])\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5719be-847e-41b0-bb1a-c2eaadc3c2b8",
   "metadata": {},
   "source": [
    "## Training the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "71ac67b0-4f81-4b73-a006-7072787c9ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.3490)\n",
      "epoch: 2 loss: tensor(0.2496)\n",
      "epoch: 3 loss: tensor(0.2507)\n",
      "epoch: 4 loss: tensor(0.2473)\n",
      "epoch: 5 loss: tensor(0.2500)\n",
      "epoch: 6 loss: tensor(0.2473)\n",
      "epoch: 7 loss: tensor(0.2480)\n",
      "epoch: 8 loss: tensor(0.2507)\n",
      "epoch: 9 loss: tensor(0.2448)\n",
      "epoch: 10 loss: tensor(0.2514)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user:id_user+batch_size]\n",
    "        v0 = training_set[id_user:id_user+batch_size]\n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
    "        s += 1.\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe4e187-68f6-4358-929e-d197a039fd16",
   "metadata": {},
   "source": [
    "## Testing the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "64a56c19-c1ba-4de9-987f-4d02d4b4aad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.2403)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user:id_user+1]\n",
    "    vt = test_set[id_user:id_user+1]\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
